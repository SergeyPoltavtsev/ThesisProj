{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run some setup code for this notebook.\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import utils as ut\n",
    "import wave\n",
    "import SoundUtils as SU\n",
    "import pylab\n",
    "import Spectograms as spectograms\n",
    "import forwardPath as forward\n",
    "import scipy.misc\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define pathes \n",
    "# content_image_path = 'neural-art-tf/images/content_spec.jpg'\n",
    "\n",
    "model_weights_path = '/Users/Sergey/Thesis/Projects/neural-art-tf/models/vgg'\n",
    "#model_weights_path = '/Users/Sergey/Thesis/Projects/ThesisProj/models/vgg'\n",
    "\n",
    "#out_dir =\"neural-art-tf/output\"\n",
    "device=\"/cpu:0\"\n",
    "\n",
    "\n",
    "path_to_params = \"/Volumes/Storage/parametersTIMIT\"\n",
    "#path_to_spectrums = \"/Volumes/Storage/spectrums/1673\"\n",
    "\n",
    "#sound\n",
    "path_to_flac = \"/Volumes/Storage/TIMIT/timit/train\"\n",
    "path_to_flac_test_folder = \"/Volumes/Storage/TIMIT/timit/train/dr1/fcjf0\"\n",
    "path_to_flac_test_folder_track = \"/Volumes/Storage/TIMIT/timit/train/dr1/fcjf0/SA1.WAV\"\n",
    "\n",
    "#temp\n",
    "temp_folder = \"/Volumes/Storage/Temp\"\n",
    "temp_phonemes_folder = \"/Volumes/Storage/TempPhonemes\"\n",
    "temp_image_to_process = \"/Volumes/Storage/processing.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load params ones\n",
    "params = np.load(model_weights_path).item()\n",
    "pathes = ut.reverseFolder(path_to_flac, \".WAV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Storage/TIMIT/timit/train/dr1/fcjf0/SA1.WAV\n",
      "Load content values...\n",
      "Load content values...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1adb5a8ca6bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mspectograms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaveRGB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_image_to_process\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetPathTIMITSPeakerAndPhoneme\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeaker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphoneme\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphone_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mforward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspectrumToArraysTIMIT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Sergey/Thesis/Projects/ThesisProj/forwardPath.pyc\u001b[0m in \u001b[0;36mspectrumToArraysTIMIT\u001b[0;34m(device, params, img, output_folder, file_name)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mcontent_image_y_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_l\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my_l\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# sess.run(y_l) is a constant numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_image_y_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Sergey/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_fetch_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Sergey/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, target_list, fetch_list, feed_dict)\u001b[0m\n\u001b[1;32m    416\u001b[0m             \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewStatus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             tf_session.TF_ExtendGraph(\n\u001b[0;32m--> 418\u001b[0;31m                 self._session, graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m    419\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetCode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m               \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Sergey/tensorflow/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc\u001b[0m in \u001b[0;36mSerializeToString\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1033\u001b[0m           'Message %s is missing required fields: %s' % (\n\u001b[1;32m   1034\u001b[0m           self.DESCRIPTOR.full_name, ','.join(self.FindInitializationErrors())))\n\u001b[0;32m-> 1035\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializePartialToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m   \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSerializeToString\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Sergey/tensorflow/lib/python2.7/site-packages/google/protobuf/internal/python_message.pyc\u001b[0m in \u001b[0;36mSerializePartialToString\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1043\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_InternalSerialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m   \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializePartialToString\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSerializePartialToString\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#because window sizr is 11, 1 in the middle and 5 on the left and 5 on the right\n",
    "phonemeOffset = spectograms.frameStep * 5\n",
    "\n",
    "for path in pathes:\n",
    "    #sentence\n",
    "    print path\n",
    "    phonemes = ut.parcePhonemeFile(path)\n",
    "    speaker = path.split(\"/\")[-2]\n",
    "\n",
    "    temp_speaker_folder = temp_folder + \"/\" + speaker\n",
    "    if not os.path.exists(temp_speaker_folder):\n",
    "        os.makedirs(temp_speaker_folder)\n",
    "    #converting to wave\n",
    "    wav_file = SU.PCM2Wav(path, temp_speaker_folder)\n",
    "    \n",
    "    for i in range(len(phonemes)):\n",
    "        phoneme = phonemes[i]\n",
    "        #Cutting one phoneme\n",
    "        if i == 0 or i == len(phonemes):\n",
    "            left = int(phoneme[0])\n",
    "            right = int(phoneme[1])\n",
    "        else:\n",
    "            left = int(phoneme[0]) - phonemeOffset\n",
    "            right = int(phoneme[1]) + phonemeOffset\n",
    "            \n",
    "        phone_file = SU.cutPhonemeChunk(wav_file, temp_phonemes_folder, left, right, phoneme[2])\n",
    "        imageRGB, minEl, maxEl = spectograms.SpectogramToImage(phone_file, temp_image_to_process)\n",
    "        \n",
    "        chunkLength = 11\n",
    "        totalFeatures = imageRGB.shape[1]\n",
    "        #The stepLength is 1 therefore the number of chunks is calculated as follows\n",
    "        numChunks = totalFeatures-chunkLength + 1\n",
    "        \n",
    "        for i in range(numChunks):\n",
    "            chunk = imageRGB[:,i:i+chunkLength,:]\n",
    "            chunk = scipy.misc.imresize(chunk, (224, 224))\n",
    "            spectograms.SaveRGB(chunk, temp_image_to_process)\n",
    "            folder, name = forward.getPathTIMITSPeakerAndPhoneme(path_to_params, speaker, phoneme[2] ,os.path.basename(phone_file), i)\n",
    "            forward.spectrumToArraysTIMIT(device, params, chunk, folder, name)\n",
    "        \n",
    "        ut.cleanFolder(temp_folder)\n",
    "        ut.cleanFolder(temp_phonemes_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = pathes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phonemes = ut.parcePhonemeFile(path)\n",
    "speaker = path.split(\"/\")[-2]\n",
    "\n",
    "temp_speaker_folder = temp_folder + \"/\" + speaker\n",
    "if not os.path.exists(temp_speaker_folder):\n",
    "    os.makedirs(temp_speaker_folder)\n",
    "#converting to wave\n",
    "wav_file = SU.PCM2Wav(path, temp_speaker_folder)\n",
    "phonemeOffset = spectograms.frameStep * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(phonemes)):\n",
    "    phoneme = phonemes[i]\n",
    "    \n",
    "    if i == 0 or i == len(phonemes):\n",
    "        left = int(phoneme[0])\n",
    "        right = int(phoneme[1])\n",
    "    else:\n",
    "        left = int(phoneme[0]) - phonemeOffset\n",
    "        right = int(phoneme[1]) + phonemeOffset\n",
    "        \n",
    "    #Cutting one phoneme\n",
    "    phone_file = SU.cutPhonemeChunk(wav_file, temp_phonemes_folder, int(phoneme[0]), int(phoneme[1]), phoneme[2])\n",
    "    imageRGB, minEl, maxEl = spectograms.SpectogramToImage(phone_file, temp_image_to_process)\n",
    "\n",
    "    ut.cleanFolder(temp_20ms_phonemes_folder)\n",
    "\n",
    "    chunkLength = 11\n",
    "    totalFeatures = imageRGB.shape[1]\n",
    "    #The stepLength is 1 therefore the number of chunks is calculated as follows\n",
    "    numChunks = totalFeatures-chunkLength + 1\n",
    "\n",
    "    for i in range(numChunks):\n",
    "        chunk = normedRGB[:,i+5:i+chunkLength,:]\n",
    "        chunk = scipy.misc.imresize(chunk, (224, 224))\n",
    "        folder, name = forward.getPathTIMITSPeakerAndPhoneme(path_to_params, speaker, phoneme[2] ,os.path.basename(phone_file), os.path.basename(chunk))\n",
    "        #forward.spectrumToArraysTIMIT(device, params, temp_image_to_process, folder, name)\n",
    "\n",
    "    ut.cleanFolder(temp_folder)\n",
    "    ut.cleanFolder(temp_phonemes_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(phonemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phonemeOffset = spectograms.frameStep * 5\n",
    "phoneme = phonemes[10]\n",
    "\n",
    "left = int(phoneme[0]) - phonemeOffset\n",
    "right = int(phoneme[1]) + phonemeOffset\n",
    "\n",
    "#Cutting one phoneme\n",
    "phone_file = SU.cutPhonemeChunk(wav_file, temp_phonemes_folder, left, right, phoneme[2])\n",
    "imageRGB, minEl, maxEl = spectograms.SpectogramToImage(phone_file, temp_image_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imageRGB.shape\n",
    "from PIL import Image\n",
    "img = Image.fromarray(imageRGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phoneme = phonemes[10]\n",
    "\n",
    "left = int(phoneme[0])\n",
    "right = int(phoneme[1])\n",
    "\n",
    "#Cutting one phoneme\n",
    "phone_file = SU.cutPhonemeChunk(wav_file, temp_phonemes_folder, left, right, phoneme[2])\n",
    "imageRGB, minEl, maxEl = spectograms.SpectogramToImage(phone_file, temp_image_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imageRGB.shape\n",
    "from PIL import Image\n",
    "img = Image.fromarray(imageRGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imageRGB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
